
import os
from langchain_community.document_loaders.csv_loader import CSVLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain
from dotenv import load_dotenv

# .env dosyasÄ±ndan API anahtarÄ±nÄ± yÃ¼kle
load_dotenv()

# Embedding'lerin kaydedileceÄŸi dizin
PERSIST_DIR = "chromadb2"

# CSV dosyasÄ±
csv_path = './yeniIntents.csv'

# Embedding ayarlarÄ±
embeddings = OpenAIEmbeddings(
    model="text-embedding-3-large",
    openai_api_key=os.getenv('OPENAI_API_KEY')
)

# EÄŸer veri daha Ã¶nce kayÄ±tlÄ±ysa oradan yÃ¼kle, deÄŸilse oluÅŸtur
if os.path.exists(PERSIST_DIR):
    print("KayÄ±tlÄ± embeddingler bulundu, yÃ¼kleniyor...")
    vectorstore = Chroma(persist_directory=PERSIST_DIR, embedding_function=embeddings)
else:
    print("Embeddingler oluÅŸturuluyor...")

    # CSV dosyasÄ±nÄ± yÃ¼kle
    loader = CSVLoader(file_path=csv_path, encoding="utf-8")
    data = loader.load()
    print("Veriler yÃ¼klendi:", len(data), "dÃ¶kÃ¼man")

    # Metinleri parÃ§alara ayÄ±r
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)
    docs = text_splitter.split_documents(data)
    print("Toplam parÃ§a sayÄ±sÄ±:", len(docs))

    # Embedding'leri oluÅŸtur ve kaydet
    vectorstore = Chroma.from_documents(
        documents=docs,
        embedding=embeddings,
        persist_directory=PERSIST_DIR
    )
    vectorstore.persist()
    print("Embeddingler baÅŸarÄ±yla kaydedildi.")

# Retriever ayarla
retriever = vectorstore.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 50}
)

# LLM modelini ayarla
llm = ChatOpenAI(
    model="gpt-3.5-turbo",
    temperature=0.3,
    max_tokens=500,
    openai_api_key=os.getenv('OPENAI_API_KEY')
)

# Sistem promptunu ayarla
system_prompt = (
    "Sen yemek tarifleri veren bir chatbot asistanÄ±sÄ±n. "
    "YanÄ±tlarÄ±n TÃ¼rkÃ§e olsun ğŸ‡¹ğŸ‡· ve aÃ§Ä±klamalarÄ±nÄ± emojilerle zenginleÅŸtir ğŸ“Œ"
    "{context}"
)

# Prompt ÅŸablonunu oluÅŸtur
prompt = ChatPromptTemplate.from_messages([
    ("system", system_prompt),
    ("human", "{input}")
])

# Soru-cevap zincirini oluÅŸtur
question_answer_chain = create_stuff_documents_chain(llm, prompt)
rag_chain = create_retrieval_chain(retriever, question_answer_chain)

def get_recipe_recommendation(query):
    """KullanÄ±cÄ±nÄ±n sorgusu iÃ§in tarif Ã¶nerisi al"""
    response = rag_chain.invoke({"input": query})
    return response["answer"]

# Test et
if __name__ == "__main__":
    test_query = "MantÄ± nasÄ±l yapÄ±lÄ±r"
    print("\nTest Sorgusu:", test_query)
    print("\nÃ–neriler:")
    print(get_recipe_recommendation(test_query))
