import os
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_fscore_support
from nltk.translate.bleu_score import sentence_bleu
from rouge import Rouge
import nltk
from langchain_community.document_loaders.csv_loader import CSVLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain
from dotenv import load_dotenv
from bert_score import score as bert_score

# Gerekli nltk verisi
nltk.download('punkt')

# .env'den API anahtarÄ±nÄ± al
load_dotenv()

# Dosya yollarÄ±
CSV_PATH = './yeniIntents.csv'
PERSIST_DIR = 'chromadb2'
TEST_PATH = './test.csv'

# Embedding ayarlarÄ±
embeddings = OpenAIEmbeddings(
    model="text-embedding-3-large",
    openai_api_key=os.getenv('OPENAI_API_KEY')
)

# Embedding'leri yÃ¼kle veya oluÅŸtur
if os.path.exists(PERSIST_DIR):
    print("âœ… KayÄ±tlÄ± embedding'ler bulundu, yÃ¼kleniyor...")
    vectorstore = Chroma(persist_directory=PERSIST_DIR, embedding_function=embeddings)
else:
    print("ğŸ”„ Embedding'ler oluÅŸturuluyor...")
    loader = CSVLoader(file_path=CSV_PATH, encoding="utf-8")
    data = loader.load()
    print("ğŸ“„ Veri yÃ¼klendi:", len(data), "dÃ¶kÃ¼man")
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)
    docs = text_splitter.split_documents(data)
    print("ğŸ“¦ ParÃ§alanan belge sayÄ±sÄ±:", len(docs))
    vectorstore = Chroma.from_documents(
        documents=docs,
        embedding=embeddings,
        persist_directory=PERSIST_DIR
    )
    vectorstore.persist()
    print("âœ… Embedding'ler baÅŸarÄ±yla kaydedildi.")

# Retriever ayarla
retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 50})

# LLM ayarlarÄ±
llm = ChatOpenAI(
    model="gpt-3.5-turbo",
    temperature=0.3,
    max_tokens=500,
    openai_api_key=os.getenv('OPENAI_API_KEY')
)

# Sistem mesajÄ±
system_prompt = (
    "Sen yemek tarifleri veren bir chatbot asistanÄ±sÄ±n. "
    "YanÄ±tlarÄ±n TÃ¼rkÃ§e olsun"
    "{context}"
)

# Prompt
prompt = ChatPromptTemplate.from_messages([
    ("system", system_prompt),
    ("human", "{input}")
])

# QA zinciri
question_answer_chain = create_stuff_documents_chain(llm, prompt)
rag_chain = create_retrieval_chain(retriever, question_answer_chain)

# Sorgu fonksiyonu
def get_recipe_recommendation(query):
    response = rag_chain.invoke({"input": query})
    return response["answer"]

# Test ve deÄŸerlendirme
if __name__ == "__main__":
    df = pd.read_csv(CSV_PATH)

    # EÄŸitim/test ayÄ±r
    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)
    test_df.to_csv(TEST_PATH, index=False)
    print(f"\nğŸ“ Test verisi '{TEST_PATH}' olarak kaydedildi. Toplam: {len(test_df)} Ã¶rnek.")

    y_true = test_df['response'].tolist()
    queries = test_df['text'].tolist()
    y_pred = []

    print("\nğŸ§ª Tahminler baÅŸlatÄ±lÄ±yor...\n")

    for i, query in enumerate(queries):
        prediction = get_recipe_recommendation(query)
        y_pred.append(prediction)
        print(f"ğŸ”¹ Soru {i+1}: {query}")
        print(f"ğŸ”¸ Tahmin: {prediction}")
        print(f"âœ… GerÃ§ek: {y_true[i]}\n")

    # Basit binary skorlar
    # binary_true = [1 if t == p else 0 for t, p in zip(y_true, y_pred)]
    # binary_pred = [1] * len(binary_true)

    # precision, recall, f1, _ = precision_recall_fscore_support(binary_true, binary_pred, average='binary')
    # print("\nğŸ“Š Klasik Metin Metrikleri:")
    # print(f"ğŸ”¹ Precision: {precision:.2f}")
    # print(f"ğŸ”¹ Recall:    {recall:.2f}")
    # print(f"ğŸ”¹ F1-score:  {f1:.2f}")

    # # ROUGE skorlarÄ±
    # rouge = Rouge()
    # rouge_scores = rouge.get_scores(y_pred, y_true, avg=True)
    # print("\nğŸ“• ROUGE SkorlarÄ±:")
    # for key, val in rouge_scores.items():
    #     print(f"{key.upper()}: {val}")

    # # BLEU
    # bleu_scores = [sentence_bleu([ref.split()], pred.split()) for ref, pred in zip(y_true, y_pred)]
    # avg_bleu = sum(bleu_scores) / len(bleu_scores)
    # print(f"\nğŸŒ Ortalama BLEU Skoru: {avg_bleu:.2f}")
    binary_true = [1 if t == p else 0 for t, p in zip(y_true, y_pred)]
    binary_pred = [1] * len(binary_true)

    precision, recall, f1, _ = precision_recall_fscore_support(binary_true, binary_pred, average='binary')
    print("\nğŸ“Š Klasik Metin Metrikleri:")
    print(f"ğŸ”¹ Precision: {precision:.2f}")
    print(f"ğŸ”¹ Recall:    {recall:.2f}")
    print(f"ğŸ”¹ F1-score:  {f1:.2f}")

    # ROUGE skorlarÄ±
    rouge = Rouge()
    rouge_scores = rouge.get_scores(y_pred, y_true, avg=True)
    print("\nğŸ“• ROUGE SkorlarÄ±:")
    for key, val in rouge_scores.items():
        print(f"{key.upper()}: {val}")

    # BLEU
    bleu_scores = [sentence_bleu([ref.split()], pred.split()) for ref, pred in zip(y_true, y_pred)]
    avg_bleu = sum(bleu_scores) / len(bleu_scores)
    print(f"\nğŸŒ Ortalama BLEU Skoru: {avg_bleu:.2f}")

    # BERTScore
    from bert_score import score as bert_score
    P, R, F1 = bert_score(y_pred, y_true, lang="tr")
    print("\nğŸ§  BERTScore:")
    print(f"ğŸ”¹ Precision: {P.mean():.4f}")
    print(f"ğŸ”¹ Recall:    {R.mean():.4f}")
    print(f"ğŸ”¹ F1-score:  {F1.mean():.4f}")